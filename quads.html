<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  <!-- Meta tags for social media banners, these should be filled in appropriatly as they are your "business card" -->
  <!-- Replace the content tag with appropriate information -->
  <meta name="description" content="">
  <meta property="og:title" content="QUADS"/>
  <meta property="og:description" content="QUADS: QUAntized Distillation Framework for Efficient Speech Language Understanding"/>
  <meta property="og:url" content=""/>
  <!-- Path to banner image, should be in the path listed below. Optimal dimenssions are 1200X630-->
  <!-- <meta property="og:image" content="static/image/your_banner_image.png" /> -->
  <meta property="og:image:width" content="1200"/>
  <meta property="og:image:height" content="630"/>


  <meta name="twitter:title" content="TWITTER BANNER TITLE META TAG">
  <meta name="twitter:description" content="TWITTER BANNER DESCRIPTION META TAG">
  <!-- Path to banner image, should be in the path listed below. Optimal dimenssions are 1200X600-->
  <meta name="twitter:image" content="static/images/your_twitter_banner_image.png">
  <meta name="twitter:card" content="summary_large_image">
  <!-- Keywords for your paper to be indexed by-->
  <meta name="keywords" content="KEYWORDS SHOULD BE PLACED HERE">
  <meta name="viewport" content="width=device-width, initial-scale=1">


  <title>QUADS</title>
  <!-- <link rel="icon" type="image/x-icon" href="static/images/favicon.ico"> -->
  <link href="https://fonts.googleapis.com/css?family=Google+Sans|Noto+Sans|Castoro"
  rel="stylesheet">

  <link rel="stylesheet" href="static/css/bulma.min.css">
  <link rel="stylesheet" href="static/css/bulma-carousel.min.css">
  <link rel="stylesheet" href="static/css/bulma-slider.min.css">
  <link rel="stylesheet" href="static/css/fontawesome.all.min.css">
  <link rel="stylesheet"
  href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css">
  <link rel="stylesheet" href="static/css/index.css">

  <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.5.1/jquery.min.js"></script>
  <script src="https://documentcloud.adobe.com/view-sdk/main.js"></script>
  <script defer src="static/js/fontawesome.all.min.js"></script>
  <script src="static/js/bulma-carousel.min.js"></script>
  <script src="static/js/bulma-slider.min.js"></script>
  <script src="static/js/index.js"></script>
</head>
<body>


  <section class="hero">
    <div class="hero-body">
      <div class="container is-max-desktop">
        <div class="columns is-centered">
          <div class="column has-text-centered">
            <h1 class="title is-1 publication-title">QUADS: QUAntized Distillation Framework for Efficient Speech Language Understanding</h1>
            <div class="is-size-5 publication-authors">
              <!-- Paper authors -->
              <span class="author-block">
                <a href="https://users.wpi.edu/~sbiswas/" target="_blank">Subrata Biswas</a><sup>*</sup>,</span>
                <span class="author-block">
                  <a href="https://users.wpi.edu/~mkhan/" target="_blank">Mohammad Nur Hossain Khan</a><sup>*</sup>,</span>
                  <span class="author-block">
                    <a href="https://users.wpi.edu/~bislam/" target="_blank">Bashima Islam</a>
                  </span>
                  </div>

                  <div class="is-size-5 publication-authors">
                    <span class="author-block">BASH Lab, Worcester Polytechnic Institute</span><br>
                    <span class="author-block" style="color: red">INTERSPEECH, 2025</span>
                    <span class="eql-cntrb"><small><br><sup>*</sup>Indicates Equal Contribution</small></span>
                  </div>

                  <div class="column has-text-centered">
                    <div class="publication-links">
                      <!-- Arxiv PDF link -->
                      <span class="link-block">
                        <a href="./index.html" target="_blank"
                        class="external-link button is-normal is-rounded is-dark">
                        <span class="icon">
                          <i class="fas fa-file-pdf"></i>
                        </span>
                          <span>Paper</span>
                        </a>
                      </span>

                      <span class="link-block">
                        <a href="https://arxiv.org/pdf/2505.14723" target="_blank"
                        class="external-link button is-normal is-rounded is-dark">
                        <span class="icon">
                          <i class="ai ai-arxiv"></i>
                        </span>
                          <span>ArXiv</span>
                        </a>
                      </span>

                  <!-- Github link -->
                  <span class="link-block">
                    <a href="https://github.com/BASHLab/RAVEN" target="_blank"
                    class="external-link button is-normal is-rounded is-dark">
                    <span class="icon">
                      <i class="fab fa-github"></i>
                    </span>
                    <span>Code</span>
                  </a>
                </span>
                </a>
              </span>
            </div>
          </div>
        </div>
      </div>
    </div>
  </div>
</section>


<!-- Paper abstract -->
<section class="section hero is-light">
  <div class="container is-max-desktop">
    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <h2 class="title is-3">Abstract</h2>
        <div class="content has-text-justified">
          <p>
            Spoken Language Understanding (SLU) systems must balance performance and efficiency, particularly in 
            resourceconstrained environments. Existing methods apply distillation
            and quantization separately, leading to suboptimal compression as distillation ignores quantization 
            constraints. We propose QUADS, a unified framework that optimizes both through
            multi-stage training with a pre-tuned model, enhancing adaptability to low-bit regimes while maintaining 
            accuracy. QUADS achieves 71.13% accuracy on SLURP and 99.20% on FSC,
            with only minor degradations of up to 5.56% compared to
            state-of-the-art models. Additionally, it reduces computational
            complexity by 60–73× (GMACs) and model size by 83–700×,
            demonstrating strong robustness under extreme quantization.
            These results establish QUADS as a highly efficient solution
            for real-world, resource-constrained SLU applications.
            Index Terms: Quantization, knowledge distillation, multi-stage
            training, speech-language understanding.
          </p>
        </div>
      </div>
    </div>
  </div>
</section>


<section class="hero is-small">
  <div class="hero-body">
    <div class="container">
      <h2 class="title is-3">Architecture</h2>
      <img src="./static/images/quads/QUADS_main_diagram.png">
      <div class="content has-text-justified">
        <strong>Schematic overview of QUADS.</strong> A two-phase framework for efficient model
        training. In the distillation phase, the student model Φ learns from the teacher model Ω
        via a combined loss strategy. The quantization phase compresses the student model’s
        weights WΦ using the codebook, where weights are grouped into clusters and refined
        using objectives that balance centroid alignment and cross-network consistency.
      </div>
    </div>
  </div>
</section>


<section class="hero is-small">
  <div class="hero-body">
    <div class="container">
      <h2 class="title is-3">Results</h2>
      <img src="./static/images/quads/main_result_table.png">
      <div class="content has-text-justified">
        <strong>Comparison of QUADS and Prior Methods on the SLURP and FSC Datasets.</strong> We report accuracy and F1-score for model
        performance, alongside GMACs and model size, to evaluate efficiency.
      </div>
    </div>
  </div>
</section>



  <section class="section" id="BibTeX">
    <div class="container is-max-desktop content">
      <h2 class="title">BibTeX</h2>
      <pre><code>
        @article{biswas2025quads,
          title={QUADS: QUAntized Distillation Framework for Efficient Speech Language Understanding},
          author={Biswas, Subrata and Khan, Mohammad Nur Hossain and Islam, Bashima},
          journal={arXiv preprint arXiv:2505.14723},
          year={2025}
        }
      </code></pre>
    </div>
  </section>


  <footer class="footer">
  <div class="container">
    <div class="columns is-centered">
      <div class="column is-8">
        <div class="content">

          <p>
            This page was built using the <a href="https://github.com/eliahuhorwitz/Academic-project-page-template" target="_blank">Academic Project Page Template</a> which was adopted from the <a href="https://nerfies.github.io" target="_blank">Nerfies</a> project page.
            You are free to borrow the source code of this website, we just ask that you link back to this page in the footer. <br> This website is licensed under a <a rel="license"  href="http://creativecommons.org/licenses/by-sa/4.0/" target="_blank">Creative
            Commons Attribution-ShareAlike 4.0 International License</a>.
          </p>

        </div>
      </div>
    </div>
  </div>
</footer>
  </body>
</html>
